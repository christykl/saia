{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAIA Demo\n",
    "In this demo, the SAIA will try to identify visual attribute reliances in an apron classifier with an injected attribute reliance on the presence of feminine-presenting individuals in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:50:01.031781Z",
     "iopub.status.busy": "2025-05-02T19:50:01.031378Z",
     "iopub.status.idle": "2025-05-02T19:51:29.340613Z",
     "shell.execute_reply": "2025-05-02T19:51:29.339345Z",
     "shell.execute_reply.started": "2025-05-02T19:50:01.031739Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from IPython import embed\n",
    "\n",
    "import torch\n",
    "import traceback\n",
    "\n",
    "from utils.call_agent import ask_agent\n",
    "from agent_api import Synthetic_System, Tools\n",
    "from utils.ExperimentEnvironment import ExperimentEnvironment\n",
    "from utils.SyntheticExemplars import SyntheticExemplars\n",
    "from utils.main_utils import MainUtils\n",
    "from utils.api_utils import str2image\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:51:31.479839Z",
     "iopub.status.busy": "2025-05-02T19:51:31.479680Z",
     "iopub.status.idle": "2025-05-02T19:51:31.575936Z",
     "shell.execute_reply": "2025-05-02T19:51:31.575255Z",
     "shell.execute_reply.started": "2025-05-02T19:51:31.479822Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = 'claude' # points to claude-3-5-sonnet-latest, we currently support 'claude', 'gpt-4o', and 'gpt-4-turbo\n",
    "base = './results/'\n",
    "path2prompts = './prompts/'\n",
    "mode = 'gender'\n",
    "bias = 'female' # demographic attribute feature reliance on feminine-presenting individuals\n",
    "bias_discount = 0.9\n",
    "path2exemplars = f'./exemplars/{mode}/{bias}/{bias_discount}_discount'\n",
    "path2save = os.path.join(base, mode, bias, f'{bias_discount}_discount')\n",
    "device_id = 0\n",
    "text2image = 'flux' # Flux image generation model\n",
    "p2p_model = 'instdiff' # InstructDiffusion image editing model\n",
    "n_experiment = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:51:31.577166Z",
     "iopub.status.busy": "2025-05-02T19:51:31.577007Z",
     "iopub.status.idle": "2025-05-02T19:51:32.755121Z",
     "shell.execute_reply": "2025-05-02T19:51:32.754282Z",
     "shell.execute_reply.started": "2025-05-02T19:51:31.577152Z"
    }
   },
   "outputs": [],
   "source": [
    "net_dissect = SyntheticExemplars(path2exemplars, path2save, mode) # precomputes synthetic dataset examplars for tools.dataset_exemplars\n",
    "with open(os.path.join(path2exemplars,'data.json'), 'r') as file: # load the benchmark model labels\n",
    "    classifier_data = json.load(file)\n",
    "\n",
    "with open(os.path.join(path2prompts,'user_adversarial_experiment.txt'), 'r') as file:\n",
    "    experiment_prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:51:32.755798Z",
     "iopub.status.busy": "2025-05-02T19:51:32.755652Z",
     "iopub.status.idle": "2025-05-02T19:52:04.865602Z",
     "shell.execute_reply": "2025-05-02T19:52:04.864943Z",
     "shell.execute_reply.started": "2025-05-02T19:51:32.755784Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_number = 0 # id of specific classifier\n",
    "item = classifier_data[classifier_number]\n",
    "gt_label = item[\"label\"].rsplit('_')[1:] # label of the classifier\n",
    "print(f\"Target concept: {gt_label[0]}\")\n",
    "print(f\"Feature reliance: {bias}\")\n",
    "obj = gt_label[0]\n",
    "experiment_path2save = os.path.join(path2save, item[\"label\"])\n",
    "os.makedirs(experiment_path2save, exist_ok=True)\n",
    "\n",
    "system = Synthetic_System(classifier_number, gt_label, mode, device_id, bias=bias, bias_discount=bias_discount) # initialize the system class\n",
    "tools = Tools(device_id, net_dissect, text2image_model_name=text2image, p2p_model_name=p2p_model) # initialize the tools class\n",
    "experiment_env = ExperimentEnvironment(system, tools, globals()) # initialize the experiment environment\n",
    "main_utils = MainUtils(path2prompts, experiment_path2save, agent, obj, tools, system, n_experiment) # initialize the main utils class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAIA's attribute reliance detection experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:52:04.866294Z",
     "iopub.status.busy": "2025-05-02T19:52:04.866134Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_rounds = 5 # max number of experiment rounds\n",
    "prev_pos_avg = None\n",
    "prev_neg_avg = None\n",
    "\n",
    "for r in range(experiment_rounds):\n",
    "    if r == 0:\n",
    "        tools.experiment_log = []\n",
    "        agent_api, user_query = main_utils.return_prompt(setting='bias_discovery')\n",
    "        tools.update_experiment_log(role='system', type=\"text\", type_content=agent_api) # update the experiment log with the system prompt\n",
    "        tools.update_experiment_log(role='user', type=\"text\", type_content=user_query) # update the experiment log with the user prompt\n",
    "        main_utils.plot_results_notebook(tools.experiment_log)\n",
    "    else:\n",
    "        tools.experiment_log = []\n",
    "        tools.update_experiment_log(role='system', type=\"text\", type_content=agent_api) # update the experiment log with the system prompt\n",
    "        prev_pos_avg, prev_neg_avg = main_utils.load_prev_context(round_num=r-1) # load the previous round's self-reflection context\n",
    "        agent_experiment = ask_agent(agent, tools.experiment_log) # ask the agent for the next experiment given the context\n",
    "        tools.update_experiment_log(role='agent', type=\"text\", type_content=str(agent_experiment)) # update the experiment log with the agent's response\n",
    "        tools.update_experiment_log(role='user', type=\"text\", type_content=experiment_prompt) # update the experiment log with the user prompt\n",
    "        main_utils.plot_results_notebook(tools.experiment_log)\n",
    "    ind = len(tools.experiment_log)\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            agent_experiment = ask_agent(agent,tools.experiment_log) # ask the agent for the next experiment given the results log to the experiment log (in the first round, the experiment log contains only the system prompt (agent api) and the user prompt (the query))\n",
    "            tools.update_experiment_log(role='agent', type=\"text\", type_content=str(agent_experiment)) # update the experiment log with the agent's response (str casting is for exceptions)\n",
    "            tools.generate_html(experiment_path2save, name=f'experiment_{n_experiment}_r{r}')\n",
    "            main_utils.plot_results_notebook(tools.experiment_log[ind:])\n",
    "            ind = len(tools.experiment_log)\n",
    "            if \"[BIAS LABEL]\" in agent_experiment: \n",
    "                break # stop the experiment if the response contains the final description. \"[BIAS LABEL]\" is the stopping signal.  \n",
    "            experiment_output = experiment_env.execute_experiment(agent_experiment) # execute the experiment\n",
    "            if experiment_output != \"\":\n",
    "                tools.update_experiment_log(role='user', type=\"text\", type_content=experiment_output) # update the experiment log with the experiment results\n",
    "        except Exception as e:\n",
    "            tools.update_experiment_log(role='user', type=\"text\", type_content=e)\n",
    "            traceback.print_exc()\n",
    "        \n",
    "    pos_avg, neg_avg, history = main_utils.save_results(round_num=r) # save the results of the current round\n",
    "    print(f\"cur positive average: {pos_avg}, cur negative average: {neg_avg}, prev positive average: {prev_pos_avg}, prev negative average: {prev_neg_avg}\")\n",
    "    with open(os.path.join(experiment_path2save, f\"history_{main_utils.experiment}.json\"), 'w') as file:\n",
    "        json.dump(history, file) # persist the history of the experiment\n",
    "    file.close()\n",
    "    # stops after 5 experiment rounds or once the early stopping heuristic is met\n",
    "    if pos_avg >= 0.7*main_utils.avg_acts and neg_avg <= 0.4*main_utils.avg_acts:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
